{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c76ae11-5140-4802-98ce-aaa03310ebd6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# model code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b99e1889-6d65-47b8-8d5d-11a78300959e",
   "metadata": {},
   "source": [
    "# all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a5c4d1b-1433-4113-92bc-6cdb9789e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "base_model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "\n",
    "class CustomResNetModel(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=3):\n",
    "        super(CustomResNetModel, self).__init__()\n",
    "        # Freeze the base ResNet model\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.resnet = base_model \n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.dense1 = nn.Linear(1000, 512) \n",
    "        self.dense2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.dense3 = nn.Linear(256, 128)\n",
    "        self.output = nn.Linear(128, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x).logits \n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.dense1(x))\n",
    "        x = torch.relu(self.dense2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.dense3(x))\n",
    "        x = self.output(x) \n",
    "        return x\n",
    "\n",
    "num_classes = 2\n",
    "custom_model = CustomResNetModel(base_model, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7026456d-03ca-4b76-8166-338c16a0e332",
   "metadata": {},
   "source": [
    "# print the structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0adceead-62c7-4809-be2e-192722d068db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomResNetModel(\n",
      "  (resnet): ResNetForImageClassification(\n",
      "    (resnet): ResNetModel(\n",
      "      (embedder): ResNetEmbeddings(\n",
      "        (embedder): ResNetConvLayer(\n",
      "          (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (encoder): ResNetEncoder(\n",
      "        (stages): ModuleList(\n",
      "          (0): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (3): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (3): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (4): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (5): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): ResNetStage(\n",
      "            (layers): Sequential(\n",
      "              (0): ResNetBottleNeckLayer(\n",
      "                (shortcut): ResNetShortCut(\n",
      "                  (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (1): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (2): ResNetBottleNeckLayer(\n",
      "                (shortcut): Identity()\n",
      "                (layer): Sequential(\n",
      "                  (0): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (1): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): ReLU()\n",
      "                  )\n",
      "                  (2): ResNetConvLayer(\n",
      "                    (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (activation): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (dense1): Linear(in_features=1000, out_features=512, bias=True)\n",
      "  (dense2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (dense3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (output): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(custom_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "871bb442-16aa-4557-a5dd-c4cd5a96a969",
   "metadata": {},
   "source": [
    "# see which parameters are trainable and which are frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3446a8b3-baae-41ed-8ffe-329b25501d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet.resnet.embedder.embedder.convolution.weight: Frozen\n",
      "resnet.resnet.embedder.embedder.normalization.weight: Frozen\n",
      "resnet.resnet.embedder.embedder.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.shortcut.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.shortcut.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.shortcut.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.0.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.1.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.0.layers.2.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.shortcut.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.shortcut.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.shortcut.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.0.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.1.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.2.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.1.layers.3.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.shortcut.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.shortcut.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.shortcut.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.0.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.1.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.2.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.3.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.4.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.2.layers.5.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.shortcut.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.shortcut.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.shortcut.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.0.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.1.layer.2.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.0.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.0.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.0.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.1.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.1.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.1.normalization.bias: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.2.convolution.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.2.normalization.weight: Frozen\n",
      "resnet.resnet.encoder.stages.3.layers.2.layer.2.normalization.bias: Frozen\n",
      "resnet.classifier.1.weight: Frozen\n",
      "resnet.classifier.1.bias: Frozen\n",
      "dense1.weight: Trainable\n",
      "dense1.bias: Trainable\n",
      "dense2.weight: Trainable\n",
      "dense2.bias: Trainable\n",
      "dense3.weight: Trainable\n",
      "dense3.bias: Trainable\n",
      "output.weight: Trainable\n",
      "output.bias: Trainable\n"
     ]
    }
   ],
   "source": [
    "for name, param in custom_model.named_parameters():\n",
    "    print(f\"{name}: {'Trainable' if param.requires_grad else 'Frozen'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f785f4-a602-4e87-a40e-76e615c97b5f",
   "metadata": {},
   "source": [
    "# training code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5711b133-2127-4ec8-8b67-b5b5fb682a8c",
   "metadata": {},
   "source": [
    "# nested cross validation code for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6923176-d72e-4d0a-9def-1ea04e8e193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../nih_dataset/test_data\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03edbde0-1a87-4150-8497-05fe28ba9b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'pneumonia': 1}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8eb43b2-cb7b-46ff-aadd-080e91be241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape: torch.Size([32, 3, 1024, 1024]), Batch y shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Show one batch\n",
    "for batch in dataloader:\n",
    "    X_batch, y_batch = batch\n",
    "    print(f\"Batch X shape: {X_batch.shape}, Batch y shape: {y_batch.shape}\")\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5472a785-c8c7-4080-bc46-490933a020b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "\n",
    "# for i in range(10):\n",
    "#     plt.subplot(1, 10, i + 1)  \n",
    "#     plt.imshow(X[i]) \n",
    "#     plt.title(f\"Label: {y[i]}\")\n",
    "#     plt.axis('off') \n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "729eb70a-5058-4045-be6a-95807142d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))      \n",
    "\n",
    "# for idx, i in enumerate(range(len(y) - 11, len(y) - 1)):\n",
    "#     plt.subplot(1, 10, idx + 1)  \n",
    "#     plt.imshow(X[i]) \n",
    "#     plt.title(f\"Label: {y[i]}\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4434d473-47d3-4d31-8ec3-97b881baff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([label for _, label in dataset]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7553a901-4edf-4175-ae67-c35d7e1dc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\n",
      "Learning Rates:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Batch Sizes:   0%|                                                                                                                                             | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.7469\n",
      "Epoch 2/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.6960\n",
      "Epoch 3/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.9394\n",
      "Epoch 4/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 1.3071\n",
      "Epoch 5/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold:  50%|████████████████                | 1/2 [02:29<02:29, 149.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.6169\n",
      "Epoch 2/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.6699\n",
      "Epoch 3/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.7225\n",
      "Epoch 4/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 1.4705\n",
      "Epoch 5/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold: 100%|████████████████████████████████| 2/2 [04:48<00:00, 143.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batch Sizes:  50%|██████████████████████████████████████████████████████████████████                                                                  | 1/2 [04:48<04:48, 288.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.8254\n",
      "Epoch 2/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.9554\n",
      "Epoch 3/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.8306\n",
      "Epoch 4/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.7330\n",
      "Epoch 5/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold:  50%|████████████████                | 1/2 [02:14<02:14, 134.73s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.5870\n",
      "Epoch 2/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 1.2687\n",
      "Epoch 3/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.9015\n",
      "Epoch 4/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 0.8880\n",
      "Epoch 5/5, Learning Rate: 0.001, Batch Size: 32\n",
      "  Training Loss: 1.1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold: 100%|████████████████████████████████| 2/2 [04:27<00:00, 133.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batch Sizes: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [09:15<00:00, 275.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                     \u001b[A\u001b[A\n",
      "Learning Rates:  33%|█████████▎                  | 1/3 [09:15<18:30, 555.32s/it]\u001b[A\n",
      "\n",
      "Batch Sizes:   0%|                                                                                                                                             | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.8752\n",
      "Epoch 2/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.7643\n",
      "Epoch 3/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.6762\n",
      "Epoch 4/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.7054\n",
      "Epoch 5/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.7256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold:  50%|████████████████                | 1/2 [02:13<02:13, 133.40s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.7706\n",
      "Epoch 2/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.7738\n",
      "Epoch 3/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.6387\n",
      "Epoch 4/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.7014\n",
      "Epoch 5/5, Learning Rate: 0.0005, Batch Size: 16\n",
      "  Training Loss: 0.6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold: 100%|████████████████████████████████| 2/2 [04:25<00:00, 132.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batch Sizes:  50%|██████████████████████████████████████████████████████████████████                                                                  | 1/2 [04:25<04:25, 265.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.7665\n",
      "Epoch 2/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.6823\n",
      "Epoch 3/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.7959\n",
      "Epoch 4/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.7331\n",
      "Epoch 5/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold:  50%|████████████████                | 1/2 [02:13<02:13, 133.95s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.6759\n",
      "Epoch 2/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.8451\n",
      "Epoch 3/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.8859\n",
      "Epoch 4/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.9545\n",
      "Epoch 5/5, Learning Rate: 0.0005, Batch Size: 32\n",
      "  Training Loss: 0.7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold: 100%|████████████████████████████████| 2/2 [04:26<00:00, 133.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batch Sizes: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [08:52<00:00, 266.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                     \u001b[A\u001b[A\n",
      "Learning Rates:  67%|██████████████████▋         | 2/3 [18:07<09:01, 541.76s/it]\u001b[A\n",
      "\n",
      "Batch Sizes:   0%|                                                                                                                                             | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7128\n",
      "Epoch 2/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7191\n",
      "Epoch 3/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7414\n",
      "Epoch 4/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7232\n",
      "Epoch 5/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold:  50%|████████████████                | 1/2 [02:07<02:07, 127.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7970\n",
      "Epoch 2/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.6648\n",
      "Epoch 3/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.7063\n",
      "Epoch 4/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.6646\n",
      "Epoch 5/5, Learning Rate: 0.0001, Batch Size: 16\n",
      "  Training Loss: 0.5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold: 100%|████████████████████████████████| 2/2 [04:13<00:00, 126.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batch Sizes:  50%|██████████████████████████████████████████████████████████████████                                                                  | 1/2 [04:13<04:13, 253.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.8123\n",
      "Epoch 2/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.6993\n",
      "Epoch 3/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.6654\n",
      "Epoch 4/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.6965\n",
      "Epoch 5/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.6160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold:  50%|████████████████                | 1/2 [02:16<02:16, 136.01s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.7133\n",
      "Epoch 2/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.9105\n",
      "Epoch 3/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.7027\n",
      "Epoch 4/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.8027\n",
      "Epoch 5/5, Learning Rate: 0.0001, Batch Size: 32\n",
      "  Training Loss: 0.7852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Inner Fold: 100%|████████████████████████████████| 2/2 [04:34<00:00, 137.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batch Sizes: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [08:47<00:00, 265.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                     \u001b[A\u001b[A\n",
      "Learning Rates: 100%|████████████████████████████| 3/3 [26:54<00:00, 535.08s/it]\u001b[A\n",
      "Outer Fold:  50%|███████████████▌               | 1/2 [27:36<27:36, 1656.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Test Accuracy: 0.5000 | Best Params: {'lr': 0.001, 'batch_size': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning Rates:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Batch Sizes:   0%|                                                                                                                                             | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Inner Fold:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Learning Rate: 0.001, Batch Size: 16\n",
      "  Training Loss: 0.7596\n",
      "Epoch 2/5, Learning Rate: 0.001, Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                                                                                     \u001b[A\u001b[A\n",
      "Outer Fold:  50%|███████████████▌               | 1/2 [28:01<28:01, 1681.95s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 42\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     44\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[18], line 22\u001b[0m, in \u001b[0;36mCustomResNetModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Pass input through ResNet\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits  \u001b[38;5;66;03m# ResNet output shape: [batch_size, 1000]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Fully connected layers with dropout and activation\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\transformers\\models\\resnet\\modeling_resnet.py:406\u001b[0m, in \u001b[0;36mResNetForImageClassification.forward\u001b[1;34m(self, pixel_values, labels, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    404\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 406\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    410\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(pooled_output)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\transformers\\models\\resnet\\modeling_resnet.py:345\u001b[0m, in \u001b[0;36mResNetModel.forward\u001b[1;34m(self, pixel_values, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    340\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    341\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[0;32m    342\u001b[0m )\n\u001b[0;32m    343\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 345\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    348\u001b[0m     embedding_output, output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states, return_dict\u001b[38;5;241m=\u001b[39mreturn_dict\n\u001b[0;32m    349\u001b[0m )\n\u001b[0;32m    351\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\transformers\\models\\resnet\\modeling_resnet.py:96\u001b[0m, in \u001b[0;36mResNetEmbeddings.forward\u001b[1;34m(self, pixel_values)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the channel dimension of the pixel values match with the one set in the configuration.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     95\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(pixel_values)\n\u001b[1;32m---> 96\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpooler\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:213\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\_jit_internal.py:624\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:830\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[1;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outer_folds = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "inner_folds = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Hyperparameter search space\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "batch_sizes = [16, 32]\n",
    "\n",
    "outer_results = []\n",
    "\n",
    "for train_idx, test_idx in tqdm(outer_folds.split(np.zeros(len(y)), y), desc=\"Outer Fold\", total=outer_folds.get_n_splits(), ncols=80):\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    test_dataset = Subset(dataset, test_idx)\n",
    "    \n",
    "    best_val_score = -float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    # Inner loop for hyperparameter tuning\n",
    "    for lr in tqdm(learning_rates, desc=\"Learning Rates\", leave=False, ncols=80):\n",
    "        for batch_size in tqdm(batch_sizes, desc=\"Batch Sizes\", leave=False):\n",
    "            val_scores = []\n",
    "\n",
    "            for inner_train_idx, val_idx in tqdm(inner_folds.split(np.zeros(len(train_idx)), y[train_idx]), desc=\"Inner Fold\", total=inner_folds.get_n_splits(), leave=False, ncols=80):\n",
    "                inner_train_dataset = Subset(dataset, train_idx[inner_train_idx])\n",
    "                val_dataset = Subset(dataset, train_idx[val_idx])\n",
    "                \n",
    "                train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "                \n",
    "                model = CustomResNetModel(base_model, num_classes)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    filter(lambda p: p.requires_grad, model.parameters()), lr=lr\n",
    "                )  \n",
    "                \n",
    "                model.train()\n",
    "                for epoch in range(5): \n",
    "                    print(f\"Epoch {epoch + 1}/5, Learning Rate: {lr}, Batch Size: {batch_size}\")\n",
    "                    epoch_loss = 0.0\n",
    "                    for inputs, labels in train_loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        epoch_loss += loss.item()\n",
    "                    \n",
    "                    print(f\"  Training Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "                \n",
    "                model.eval()\n",
    "                all_preds = []\n",
    "                all_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in val_loader:\n",
    "                        outputs = model(inputs)\n",
    "                        preds = torch.argmax(outputs, dim=1)\n",
    "                        all_preds.append(preds)\n",
    "                        all_labels.append(labels)\n",
    "                \n",
    "                all_preds = torch.cat(all_preds)\n",
    "                all_labels = torch.cat(all_labels)\n",
    "                val_accuracy = accuracy_score(all_labels.cpu(), all_preds.cpu())\n",
    "                val_scores.append(val_accuracy)\n",
    "            \n",
    "            avg_val_score = np.mean(val_scores)\n",
    "            \n",
    "            if avg_val_score > best_val_score:\n",
    "                best_val_score = avg_val_score\n",
    "                best_params = {\"lr\": lr, \"batch_size\": batch_size}\n",
    "                best_model = model\n",
    "    \n",
    "    # Test the best model on the outer test set\n",
    "    test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
    "    best_model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = best_model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    test_accuracy = accuracy_score(all_labels.cpu(), all_preds.cpu())\n",
    "    outer_results.append(test_accuracy)\n",
    "\n",
    "    print(f\"Fold Test Accuracy: {test_accuracy:.4f} | Best Params: {best_params}\")\n",
    "\n",
    "print(f\"Nested CV Test Accuracy: {np.mean(outer_results):.4f} ± {np.std(outer_results):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b43b35-da43-4554-aa55-197f8bad2bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
